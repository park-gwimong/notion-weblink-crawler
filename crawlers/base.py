# -*- coding: utf-8 -*-
"""
í¬ë¡¤ëŸ¬ ë² ì´ìŠ¤ í´ë˜ìŠ¤
ëª¨ë“  í¬ë¡¤ëŸ¬ê°€ ìƒì†ë°›ëŠ” ì¶”ìƒ í´ë˜ìŠ¤
"""

from abc import ABC, abstractmethod
from datetime import datetime
from typing import List, Dict, Any
from playwright.sync_api import sync_playwright, Page

import sys
sys.path.insert(0, '..')
from config import MAX_POSTS_PER_SOURCE, PLAYWRIGHT_TIMEOUT


class Post:
    """ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ë°ì´í„° í´ë˜ìŠ¤"""

    def __init__(self, title: str, url: str, summary: str = "",
                 date: str = "", source: str = ""):
        self.title = title
        self.url = url
        self.summary = summary
        self.date = date or datetime.now().strftime('%Y.%m.%d')
        self.source = source

    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            'title': self.title,
            'url': self.url,
            'summary': self.summary,
            'date': self.date,
            'source': self.source,
        }


class BaseCrawler(ABC):
    """í¬ë¡¤ëŸ¬ ë² ì´ìŠ¤ í´ë˜ìŠ¤"""

    # ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ ì •ì˜í•´ì•¼ í•  ì†ì„±
    name: str = ""           # í¬ë¡¤ëŸ¬ ì´ë¦„ (ì˜ˆ: "D2", "ì¹´ì¹´ì˜¤")
    source_id: str = ""      # ì†ŒìŠ¤ ID (ì˜ˆ: "d2", "kakao")
    base_url: str = ""       # ë¸”ë¡œê·¸ ê¸°ë³¸ URL

    def __init__(self):
        self.max_posts = MAX_POSTS_PER_SOURCE
        self.timeout = PLAYWRIGHT_TIMEOUT

    @abstractmethod
    def parse_posts(self, page: Page) -> List[Post]:
        """
        í˜ì´ì§€ì—ì„œ í¬ìŠ¤íŠ¸ ëª©ë¡ íŒŒì‹± (ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ êµ¬í˜„)

        Args:
            page: Playwright í˜ì´ì§€ ê°ì²´

        Returns:
            Post ê°ì²´ ë¦¬ìŠ¤íŠ¸
        """
        pass

    def fetch(self) -> List[Dict[str, Any]]:
        """ë¸”ë¡œê·¸ì—ì„œ ìµœì‹  ê¸€ ê°€ì ¸ì˜¤ê¸°"""
        try:
            with sync_playwright() as p:
                browser = p.chromium.launch(headless=True)
                page = browser.new_page()

                print(f"  ğŸŒ {self.name} í˜ì´ì§€ ë¡œë”© ì¤‘...")
                page.goto(self.base_url, wait_until="networkidle")

                posts = self.parse_posts(page)
                browser.close()

                print(f"  âœ… {len(posts)}ê°œ ê¸€ íŒŒì‹± ì™„ë£Œ")
                return [post.to_dict() for post in posts[:self.max_posts]]

        except Exception as e:
            print(f"âŒ {self.name} í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return []

    def _make_absolute_url(self, href: str) -> str:
        """ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜"""
        if href.startswith('http'):
            return href
        if href.startswith('/'):
            # base_urlì—ì„œ ë„ë©”ì¸ ì¶”ì¶œ
            from urllib.parse import urlparse
            parsed = urlparse(self.base_url)
            return f"{parsed.scheme}://{parsed.netloc}{href}"
        return href
